<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Our method learns to control the layout of images generated by large pre-trained models without any training or fine-tuning.">
  <meta name="keywords" content="Layout-Guidance, Generative Model, Diffusion, Cross-attention">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Training-Free Layout Control with Cross-Attention Guidance.</title>

  <meta property="og:image" content="https://silent-chen.github.io/layout-guidance/resources/teaser.png"/>
	<meta property="og:title" content="Training-Free Layout Control with Cross-Attention Guidance." />
	<meta property="og:description" content="Our method learns to control the layout of images generated by large pre-trained models without any training or fine-tuning." />
  <!-- Twitter automatically scrapes this. Go to https://cards-dev.twitter.com/validator?
      if you update and want to force Twitter to re-scrape. -->
  <meta property="twitter:card"          content="summary" />
  <meta property="twitter:title"         content="Training-Free Layout Control with Cross-Attention Guidance." />
  <meta property="twitter:description"   content="Our method learns to control the layout of images generated by large pre-trained models without any training or fine-tuning." />
  <meta property="twitter:image"         content="https://silent-chen.github.io/layout-guidance/resources/teaser.png" />

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-VFNFH9CKNX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-VFNFH9CKNX');
  </script>
  <script type="module"
  src="https://gradio.s3-us-west-2.amazonaws.com/3.23.0/gradio.js">
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./resources/pikachu.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <!-- <script src="./static/js/index.js"></script> -->
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">


      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title" style="font-size: 2.2rem;"> Training-Free Layout Control with Cross-Attention Guidance</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://silent-chen.github.io">Minghao Chen</a>,
            </span>
            <span class="author-block">
              <a href="">Iro Laina</a>,
            </span>
            <span class="author-block">
              <a href="https://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Visual Geometry Group, University of Oxford</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/silent-chen/layout-guidance/blob/gh-page/resources/LayoutGuidanceVid.mp4"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-youtube"></i>-->
<!--                  </span>-->
<!--                  <span>Video</span>-->
<!--                </a>-->
<!--              </span>-->
              <span class="link-block">
                <a href="https://github.com/silent-chen/layout-guidance"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
<!--              <span class="link-block">-->
<!--                <a href=""-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="far fa-images"></i>-->
<!--                  </span>-->
<!--                  <span>Data</span>-->
<!--                </a>-->
<!--              </span>-->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted controls loop playsinline height="100%">
        <source src="resources/LayoutGuidanceVid.mp4"
                type="video/mp4">
      </video>

<!--      <video id="teaser" autoplay muted loop playsinline height="100%">-->
<!--        <source src="resources/teaser.pdf"-->
<!--                type="video/mp4">-->
<!--      </video>-->
        <p>&nbsp;</p>
        <p>&nbsp;</p>
          <img src="resources/teaser.png" alt="teaser"> <br>
      <h2 class="subtitle">
        We present a method for controlling the layout of images generated by large pre-trained text-to-image models by guiding the cross-attention patterns produced by the model in a spatially-directed manner. Our method requires no further training or finetuning.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Recent diffusion-based generators can produce high-quality images based only on textual prompts. However, they do not correctly interpret instructions that specify the spatial layout of the composition. We propose a simple approach that can achieve robust layout control without requiring training or fine-tuning the image generator. Our technique, which we call layout guidance, manipulates the cross-attention layers that the model uses to interface textual and visual information and steers the reconstruction in the desired direction given, e.g., a user-specified layout. In order to determine how to best guide attention, we study the role of different attention maps when generating images and experiment with two alternative strategies, forward and backward guidance. We evaluate our method quantitatively and qualitatively with several experiments, validating its effectiveness. We further demonstrate its versatility by extending layout guidance to the task of editing the layout and context of a given real image.        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Demo</h2>
        <div class="content has-text-justified">
        <gradio-app src="https://silentchen-layout-guidance.hf.space"></gradio-app>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">

        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            We present two types of guidance for controlling the image layout -- forward and backward. In forward guidance, we use a smooth windowing function to bias the original cross-attention map of a specific token towards a user-specified region (such as a bounding box), to "force" the generated image to conform to the desired layout. Backward guidance involves calculating a loss between the cross-attention and bounding box to evaluate whether the attention map follows the desired pattern and updates the latent using back-propagation to guide the attention to focus on a specific region.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="resources/Overview.png" width="60%" alt="overview"> <br>
        </div>
        <br>

        <h2 class="title is-3">Comparison to Text-to-Image Generation Methods</h2>
        <div class="content has-text-justified">
          <p>
            Our method, built on top of Stable Diffusion, achieves image generation with correct spatial relationships. Some examples are from <span><a href="https://visort2i.github.io/">here</a>.
 </span>
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="resources/visor_addition_results_2.png" width="80%" alt="visor_addition_results_2"> <br>
        </div>
        <br>


        <h2 class="title is-3">Real Image Editing</h2>
        <div class="content has-text-justified">
          <p>
            We achieve real image editing based on Dreambooth and Text Inversion. Specifically, we can change the context, location and size of the objects in the original image.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="resources/real_image_editing.png" width="80%" alt="real image editing"> <br>
        </div>
        <br>

      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{chen2023trainingfree,
      title={Training-Free Layout Control with Cross-Attention Guidance},
      author={Minghao Chen and Iro Laina and Andrea Vedaldi},
      journal={arXiv preprint arXiv:2304.03373},
      year={2023}
}</code></pre>
  </div>
</section>

<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    <p>
      This research is supported by ERC-CoG UNION 101001212.
    </p>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This webpage template is adapted from <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0 License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
