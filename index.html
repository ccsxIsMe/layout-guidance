<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Our method learns to control the layout of images generated by large pre-trained models without any training or fine-tuning.">
  <meta name="keywords" content="Layout-Guidance, Generative Model, Diffusion, Cross-attention">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Training-Free Layout Control with Cross-Attention Guidance.</title>

  <meta property="og:image" content="https://silent-chen.github.io/layout-guidance/resources/teaser.png"/>
	<meta property="og:title" content="Training-Free Layout Control with Cross-Attention Guidance." />
	<meta property="og:description" content="Our method learns to control the layout of images generated by large pre-trained models without any training or fine-tuning." />
  <!-- Twitter automatically scrapes this. Go to https://cards-dev.twitter.com/validator?
      if you update and want to force Twitter to re-scrape. -->
  <meta property="twitter:card"          content="summary" />
  <meta property="twitter:title"         content="Training-Free Layout Control with Cross-Attention Guidance." />
  <meta property="twitter:description"   content="Our method learns to control the layout of images generated by large pre-trained models without any training or fine-tuning." />
  <meta property="twitter:image"         content="https://silent-chen.github.io/layout-guidance/resources/teaser.png" />

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-VFNFH9CKNX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-VFNFH9CKNX');
  </script>
  <script type="module"
  src="https://gradio.s3-us-west-2.amazonaws.com/3.23.0/gradio.js">
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./resources/pikachu.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <!-- <script src="./static/js/index.js"></script> -->
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
<!--      <div class="columns is-centered">-->
<!--        <video id="banner" autoplay muted loop playsinline height="100%">-->
<!--          <source src="resources/xxx.mp4"-->
<!--                  type="video/mp4">-->
<!--        </video>-->
<!--      </div>-->
<!--      <br>-->

      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title" style="font-size: 2.2rem;"> Training-Free Layout Control with Cross-Attention Guidance</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://silent-chen.github.io">Minghao Chen</a>,
            </span>
            <span class="author-block">
              <a href="https://campar.in.tum.de/Main/IroLaina">Iro Laina</a>,
            </span>
            <span class="author-block">
              <a href="https://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Visual Geometry Group, University of Oxford</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="xxx"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
<!--              <span class="link-block">-->
<!--                <a href=""-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="far fa-images"></i>-->
<!--                  </span>-->
<!--                  <span>Data</span>-->
<!--                </a>-->
<!--              </span>-->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
    <img src="resources/teaser.png" alt="teaser"> <br>
<!--      <video id="teaser" autoplay muted loop playsinline height="100%">-->
<!--        <source src="resources/teaser.pdf"-->
<!--                type="video/mp4">-->
<!--      </video>-->
      <h2 class="subtitle">
        Our method manage to control of layout of images generated by large pretrained Text-to-Image diffusion models
        <span style="color:red">without training</span> through the layout guidance performed on the cross-attention maps.
      </h2>

    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Recent diffusion-based generators can produce high-quality images based only on textual prompts. However, they do not correctly interpret instructions that specify the spatial layout of the composition. We propose a simple approach that can achieve robust layout control without requiring training or fine-tuning the image generator. Our technique, which we call layout guidance, manipulates the cross-attention layers that the model uses to interface textual and visual information, and steers the reconstruction in the desired direction given, e.g., a user-specified layout. In order to determine how to best guide attention, we study the role of different attention maps for generating an image and experiment with two alternative strategies, forward and backward guidance. We evaluate our method quantitatively and qualitatively in several experiments, validating its effectiveness. We further demonstrate its flexibility by applying it to models that use image generators for various tasks; in particular, we demonstrate how this technique can be used to edit the layout of a given real image.          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="resources/LayoutGuidanceVid.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Demo</h2>
        <div class="content has-text-justified">
        <gradio-app src="https://ddc0df4552e2c32356.gradio.live"></gradio-app>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">

        <h2 class="title is-3">Oveview</h2>
        <div class="content has-text-justified">
          <p>
            We provide two different guidance, forward and backward, for layout control. Forward guidance combine the original cross-attention map with an additional inject attention as the layout guidance. On the other hand, backward guidance compute the loss between the cross-attention and bounding box following by back-propagation updating the latent variable directly.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="resources/Overview.png" width="60%" alt="overview"> <br>
        </div>
        <br>

        <h2 class="title is-3">Examples under VISOR</h2>
        <div class="content has-text-justified">
          <p>
            The model achieve to generate images with correct spatial relationship under VISOR protocol. Some examples are from <span><a href="https://visort2i.github.io/">here</a>.
 </span>
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="resources/visor_addition_results_2.png" width="80%" alt="visor_addition_results_2"> <br>
        </div>
        <br>


        <h2 class="title is-3">Real Image Editing</h2>
        <div class="content has-text-justified">
          <p>
            We achieve real image editing based on Dreambooth and Text Inversion. Specifically, we can change the context, location and size of the objects in the original image.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="resources/real_image_editing.png" width="80%" alt="real image editing"> <br>
        </div>
        <br>

      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{chen2023layout,
  author    = {Minghao Chen and Iro Laina and Andrea Vedaldi},
  title     = {Training-Free Layout Control with Cross-Attention Guidance},
  journal   = {arxiv},
  year      = {2023.3}
}</code></pre>
  </div>
</section>

<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
<!--    <p>-->
<!--      We would like to thank the authors of <a href="https://github.com/NVlabs/nvdiffrec">nvdiffrec</a> for open-sourcing the code for DMTet and rendering. We are also grateful to Tengda Han, Shu Ishida, Dylan Campbell, Eldar Insafutdinov, Luke Melas-Kyriazi, Ragav Sachdeva and Sagar Vaze for insightful discussions, and Guanqi Zhan and Jaesung Huh for proofreading.-->
<!--    </p>-->
    <p>
      This research is supported by ERC-CoG UNION 101001212.
    </p>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This webpage template is adapted from <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0 License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
